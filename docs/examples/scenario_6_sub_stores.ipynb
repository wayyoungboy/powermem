{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 6: Sub Stores - Memory Partitioning\n",
    "\n",
    "This scenario demonstrates powermem's sub stores feature - partitioning different types of memories into separate storage for more efficient querying and management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Completed Scenario 1\n",
    "- Installed powermem\n",
    "- Configured OceanBase database (or other storage backend that supports sub stores)\n",
    "- Configured LLM and Embedding services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Sub Stores\n",
    "\n",
    "Sub stores allow you to:\n",
    "- Store different types of memories in independent tables\n",
    "- Configure independent embedding dimensions and services for each sub store\n",
    "- Automatically route to the correct storage based on metadata\n",
    "- Migrate existing data to sub stores\n",
    "- Improve query performance and resource utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Important: Sub Store Activation\n",
    "\n",
    "**Before you can use sub stores, you MUST call `migrate_to_sub_store()` at least once for each sub store, even if you have no data to migrate.** This initializes the sub store and marks it as ready for use.\n",
    "\n",
    "```python\n",
    "# Even with no data to migrate, you must activate each sub store:\n",
    "memory.migrate_all_sub_stores(delete_source=False)\n",
    "```\n",
    "\n",
    "After activation:\n",
    "- New memories with matching metadata will be automatically routed to the sub store\n",
    "- Queries with matching filters will automatically route to the sub store\n",
    "- Without this activation step, sub stores remain dormant and unused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configure Sub Stores\n",
    "\n",
    "First, let's create a Memory instance with sub stores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from powermem import Memory\n",
    "import os\n",
    "\n",
    "# Configure main storage and sub stores\n",
    "config = {\n",
    "    \"database\": {\n",
    "        \"provider\": \"oceanbase\",\n",
    "        \"config\": {\n",
    "            \"collection_name\": \"main_memories\",\n",
    "            \"embedding_model_dims\": 1536,\n",
    "            \"host\": os.getenv(\"OCEANBASE_HOST\", \"127.0.0.1\"),\n",
    "            \"port\": int(os.getenv(\"OCEANBASE_PORT\", \"2881\")),\n",
    "            \"user\": os.getenv(\"OCEANBASE_USER\", \"root@test_tenant\"),\n",
    "            \"password\": os.getenv(\"OCEANBASE_PASSWORD\", \"\"),\n",
    "            \"db_name\": os.getenv(\"OCEANBASE_DATABASE\", \"powermem\"),\n",
    "        }\n",
    "    },\n",
    "    \"llm\": {\n",
    "        \"provider\": \"qwen\",\n",
    "        \"config\": {\n",
    "            \"model\": \"qwen-max\",\n",
    "            \"api_key\": os.getenv(\"DASHSCOPE_API_KEY\", \"your-api-key\"),\n",
    "        }\n",
    "    },\n",
    "    \"embedder\": {\n",
    "        \"provider\": \"qwen\",\n",
    "        \"config\": {\n",
    "            \"model\": \"text-embedding-v4\",\n",
    "            \"embedding_dims\": 1536,\n",
    "            \"api_key\": os.getenv(\"DASHSCOPE_API_KEY\", \"your-api-key\"),\n",
    "        }\n",
    "    },\n",
    "    # Configure sub stores\n",
    "    \"sub_stores\": [\n",
    "        {\n",
    "            \"collection_name\": \"working_memories\",\n",
    "            \"routing_filter\": {\"memory_type\": \"working\"},\n",
    "            \"embedding_model_dims\": 1536,\n",
    "        },\n",
    "        {\n",
    "            \"collection_name\": \"episodic_memories\",\n",
    "            \"routing_filter\": {\"memory_type\": \"episodic\"},\n",
    "            \"embedding_model_dims\": 1536,\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Initialize Memory\n",
    "memory = Memory(config=config)\n",
    "print(\"‚úì Memory initialized successfully with 2 sub stores\")\n",
    "print(\"  - Main store: main_memories (for semantic memories)\")\n",
    "print(\"  - Sub store 0: working_memories (for working memories)\")\n",
    "print(\"  - Sub store 1: episodic_memories (for episodic memories)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Add Different Types of Memories\n",
    "\n",
    "Let's add different types of memories to the main store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = \"demo_user\"\n",
    "\n",
    "# Add semantic memories (long-term knowledge, stays in main store)\n",
    "print(\"1. Adding semantic memories (knowledge)...\")\n",
    "memory.add(\n",
    "    messages=\"Python is a high-level programming language known for its simplicity\",\n",
    "    metadata={\"memory_type\": \"semantic\", \"topic\": \"programming\"},\n",
    "    user_id=user_id\n",
    ")\n",
    "print(\"  ‚úì Added\")\n",
    "\n",
    "# Add working memories (short-term tasks)\n",
    "print(\"\\n2. Adding working memories (tasks)...\")\n",
    "memory.add(\n",
    "    messages=\"Meeting scheduled at 3 PM today\",\n",
    "    metadata={\"memory_type\": \"working\", \"importance\": \"medium\"},\n",
    "    user_id=user_id\n",
    ")\n",
    "print(\"  ‚úì Added\")\n",
    "\n",
    "# Add episodic memories (personal experiences)\n",
    "print(\"\\n3. Adding episodic memories (experiences)...\")\n",
    "memory.add(\n",
    "    messages=\"Last summer I visited Paris and saw the Eiffel Tower\",\n",
    "    metadata={\"memory_type\": \"episodic\", \"time\": \"2024-07\"},\n",
    "    user_id=user_id\n",
    ")\n",
    "print(\"  ‚úì Added\")\n",
    "\n",
    "print(\"\\n‚úì Memories added (currently all in main store)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Migrate Data to Sub Stores (REQUIRED)\n",
    "\n",
    "Now let's migrate data to the respective sub stores. **This step is mandatory to activate sub stores:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting data migration to sub stores...\\n\")\n",
    "\n",
    "# Migrate working memories to sub store 0\n",
    "# ‚ö†Ô∏è IMPORTANT: This call is REQUIRED even if you have no data to migrate!\n",
    "# It activates the sub store and marks it as ready for use.\n",
    "print(\"1. Migrating working memories to sub store 0...\")\n",
    "working_count = memory.migrate_to_sub_store(\n",
    "    sub_store_index=0,\n",
    "    delete_source=True  # Delete from main store after migration\n",
    ")\n",
    "print(f\"  ‚úì Migrated {working_count} working memories\")\n",
    "print(f\"  ‚úì Sub store 0 is now ACTIVE and ready for routing\")\n",
    "\n",
    "# Migrate episodic memories to sub store 1\n",
    "print(\"\\n2. Migrating episodic memories to sub store 1...\")\n",
    "episodic_count = memory.migrate_to_sub_store(\n",
    "    sub_store_index=1,\n",
    "    delete_source=True\n",
    ")\n",
    "print(f\"  ‚úì Migrated {episodic_count} episodic memories\")\n",
    "print(f\"  ‚úì Sub store 1 is now ACTIVE and ready for routing\")\n",
    "\n",
    "print(\"\\n‚úì Migration completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Important Note About Sub Store Activation\n",
    "\n",
    "**Why is `migrate_to_sub_store()` required?**\n",
    "\n",
    "1. **Initialization**: Sub stores are created during Memory initialization, but they start in a dormant state\n",
    "2. **Activation**: Calling `migrate_to_sub_store()` marks the sub store as \"ready\" and enables routing\n",
    "3. **No data required**: You can call it with `delete_source=False` even if there's nothing to migrate\n",
    "4. **One-time operation**: Once activated, the sub store remains active for all future operations\n",
    "\n",
    "**Without calling `migrate_to_sub_store()`:**\n",
    "- Sub stores exist but are not used\n",
    "- All new memories go to the main store\n",
    "- Queries don't route to sub stores\n",
    "- The routing filters are ignored\n",
    "\n",
    "**After calling `migrate_to_sub_store()`:**\n",
    "- Sub store is marked as active and ready\n",
    "- New memories automatically route based on metadata\n",
    "- Queries automatically route based on filters\n",
    "- The sub store is fully functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Query After Migration (Automatic Routing)\n",
    "\n",
    "After migration, queries automatically route to the correct sub store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Querying after migration (automatic routing)\\n\")\n",
    "\n",
    "# Query working memories (should route to sub store 0)\n",
    "print(\"1. Querying working memories (routes to sub store 0)...\")\n",
    "results = memory.search(\n",
    "    query=\"today's schedule\",\n",
    "    filters={\"memory_type\": \"working\"},\n",
    "    user_id=user_id,\n",
    "    limit=5\n",
    ")\n",
    "results_list = results.get(\"results\", [])\n",
    "print(f\"  Found {len(results_list)} results\")\n",
    "for i, result in enumerate(results_list, 1):\n",
    "    source = result.get('_source_store', 'unknown')\n",
    "    print(f\"  {i}. [{source}] {result['memory'][:50]}\")\n",
    "\n",
    "# Query episodic memories (should route to sub store 1)\n",
    "print(\"\\n2. Querying episodic memories (routes to sub store 1)...\")\n",
    "results = memory.search(\n",
    "    query=\"past memories\",\n",
    "    filters={\"memory_type\": \"episodic\"},\n",
    "    user_id=user_id,\n",
    "    limit=5\n",
    ")\n",
    "results_list = results.get(\"results\", [])\n",
    "print(f\"  Found {len(results_list)} results\")\n",
    "for i, result in enumerate(results_list, 1):\n",
    "    source = result.get('_source_store', 'unknown')\n",
    "    print(f\"  {i}. [{source}] {result['memory'][:50]}\")\n",
    "\n",
    "# Query semantic memories (should query main store)\n",
    "print(\"\\n3. Querying semantic memories (queries main store)...\")\n",
    "results = memory.search(\n",
    "    query=\"programming knowledge\",\n",
    "    filters={\"memory_type\": \"semantic\"},\n",
    "    user_id=user_id,\n",
    "    limit=5\n",
    ")\n",
    "results_list = results.get(\"results\", [])\n",
    "print(f\"  Found {len(results_list)} results\")\n",
    "for i, result in enumerate(results_list, 1):\n",
    "    source = result.get('_source_store', 'main')\n",
    "    print(f\"  {i}. [{source}] {result['memory'][:50]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Add New Memories (Automatic Routing)\n",
    "\n",
    "New memories are automatically routed to the correct sub store (because we activated them in Step 3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adding new memories (testing automatic routing)\\n\")\n",
    "\n",
    "# Add new working memory (should route to sub store 0)\n",
    "print(\"1. Adding new working memory...\")\n",
    "memory.add(\n",
    "    messages=\"Remember to call the dentist tomorrow morning\",\n",
    "    metadata={\"memory_type\": \"working\", \"importance\": \"high\"},\n",
    "    user_id=user_id\n",
    ")\n",
    "print(\"  ‚úì Automatically routed to sub store 0\")\n",
    "\n",
    "# Add new episodic memory (should route to sub store 1)\n",
    "print(\"\\n2. Adding new episodic memory...\")\n",
    "memory.add(\n",
    "    messages=\"I graduated from university in 2020\",\n",
    "    metadata={\"memory_type\": \"episodic\", \"time\": \"2020\"},\n",
    "    user_id=user_id\n",
    ")\n",
    "print(\"  ‚úì Automatically routed to sub store 1\")\n",
    "\n",
    "# Add new semantic memory (should stay in main store)\n",
    "print(\"\\n3. Adding new semantic memory...\")\n",
    "memory.add(\n",
    "    messages=\"Docker is a platform for developing and deploying containerized applications,I love using Docker\",\n",
    "    metadata={\"memory_type\": \"semantic\", \"topic\": \"technology\"},\n",
    "    user_id=user_id\n",
    ")\n",
    "print(\"  ‚úì Automatically routed to main store\")\n",
    "\n",
    "print(\"\\n‚úì All new memories correctly routed to their respective stores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this scenario, we learned:\n",
    "- ‚úì How to configure and initialize sub stores\n",
    "- ‚úì Adding different types of memories\n",
    "- ‚úì **REQUIRED**: Calling `migrate_to_sub_store()` to activate sub stores\n",
    "- ‚úì Migrating data to sub stores\n",
    "- ‚úì Automatic query routing\n",
    "- ‚úì Automatic routing for new memories\n",
    "\n",
    "### Key Takeaway: Sub Store Activation\n",
    "\n",
    "**Remember**: Sub stores must be explicitly activated by calling `migrate_to_sub_store()` at least once, even if you have no data to migrate. Without this activation step, sub stores remain dormant and unused, and all operations will continue using only the main store.\n",
    "\n",
    "### Sub stores Benefits\n",
    "\n",
    "- Optimize storage costs (different embedding dimensions)\n",
    "- Improve query performance (data partitioning)\n",
    "- Better data organization (separation by type)\n",
    "- Flexible management strategies (independent configuration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
